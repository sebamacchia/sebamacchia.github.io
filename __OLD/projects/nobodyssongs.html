<!doctype html>
<html>

<head>
    <title>Seba Macc</title> <!-- META -->
    <meta charset="utf-8">
    <link rel="alternate" type="application/rss+xml" title="Seba Macc" href="/feed.xml <link rel=" icon"="">
    <link rel="mask-icon" href="fonts/safari-tab-icon.svg" color="#000000">
    <meta name="description" content="An open source blog for inspiring and creative online work!">
    <meta name="viewport" content="width=device-width, initial-scale=1"> <!-- CSS -->
    <link href="../css/stylesheet.css" rel="stylesheet" type="text/css">
</head>

<body>

    <div class="content-wrapper">
        <div class="tile-grid"> <noscript>

                <style>
                    header {
                        display: none;
                    }

                </style>
                <div class="tile noscript">
                    <h1>Seba Macc</h1>
                    <h2>It looks like you don't have JavaScript enabled.</h2>
                    <ul>
                        <li>Nearly everything on this site requires it.</li>
                        <li>So you should turn JavaScript on if you want to see anymore content.</li>
                    </ul>
                </div>

            </noscript>
        </div>
        <div class="tile3 noscript3">
            <a href="javascript:history.back()">←</a>
        </div>

        <div class="content-wrapper">
            <div class="tile-grid">
                <div class="tile2 noscript2">
                    <h4>Making an Album with Music Transformer</h1>
                        <h5>
                            <br>
                            (This Post was originaly publish in the <a
                                href="https://magenta.tensorflow.org/nobodys-songs">Google Magenta Blog.</a>)

                            <br>
                            <br>
                            <a target="_blank" href="https://sebamacc.bandcamp.com/album/nobodys-songs">Nobody’s
                                songs</a> is an album composed with the help of <a target="_blank"
                                href="https://magenta.tensorflow.org/piano-transformer">Magenta’s Music
                                Transformer</a> neural
                            <a href=""></a>
                            network. In this post I will write about the process I went through to make an album with
                            artificial intelligence and all the decisions I took along the journey.
                            <br>
                            <br>
                            <h6>Motivation
                            </h6>
                            <br>
                            <h5>The initial idea was to use a generative model from a deep neural network architecture
                                to
                                create music that has good enough harmony and melody and is acceptable as music composed
                                by
                                a human being.

                                I usually work with organic kind of sound using samplers of acoustic instruments so
                                symbolic
                                representation (MIDI) was a good option to use in a DAW (my choice: Ableton Live). In
                                order
                                to simplify the process the idea was to use single track polyphonic MIDIs.

                                About the style I thought of the French classical composer Erik Satie, and particularly
                                the
                                compositions that he called “furniture music”, sounds that were designed to be heard but
                                not
                                listened to, what we call nowadays background music.

                                So I used Onsets and Frames to convert some wavs of Satie’s music to MIDI files. Even
                                though
                                I tried some techniques to do data augmentation, the MIDI dataset was not big enough to
                                train a deep neural network so the results training a basic LSTM network was not good
                                (as I
                                expected).
                            </h5>
                            <br>
                            <h6>Using Music Transformer</h6>
                            <br>
                            <h5>After several tests with different options (baseline LSTM, performance RNN, MusicVAE) I
                                was surprised by the initial results I obtained using the Music Transformer colab
                                implementation. The expressing timing and dynamics were much better than the other
                                models I tried. Also, the transformer model is able to capture repeating patterns in a
                                way LSTMs cannot so finally I decided to go deep into the notebook and play with the
                                model.</h5>
                            <br>
                            <h5>In the colab there are two models: unconditioned and melody-conditioned. The
                                unconditional transformer has two options: getting a sample from scratch and generating
                                a continuation.</h5>
                            <br>
                            <h5>I worked with the last option (continuation generator) using the Satie’s MIDIs as
                                primers.</h5>
                            <br>
                            <h5>
                                The version of the model in the colab allows no control over how long the generated
                                continuation should be, it releases an end token to decide when to stop so I got
                                sometimes just a 10 sec midi primer generates 2 min continuation but a 40 sec long stop
                                suddenly adding just 10 extra sec.
                                <br>
                                By doing several tests I was able to prove that a primer with fewer notes generated
                                longer continuations and that approx. 30 sec of MIDI premier was enough to “inspire” the
                                model to generate some decent continuations.
                            </h5>
                            <br>
                            <h6>The curator is the new composer</h6>
                            <br>
                            <h5>One of the main artist roles in the process of the creation using this kind of model is
                                the selection of the many outputs the model generates. The artist must sift through all
                                of them and select those that are “good enough” to use to generate the final artwork.
                                <br>
                                I got more than a hundred of midi continuations with different Satie midi primers, some
                                of them not so good:
                                <br>
                                <br>
                                <audio controls>
                                    <source src="nobodys/discarted1.mp3" type="audio/mpeg">
                                    Your browser does not support the audio element.
                                </audio>
                                <br>
                                Many aren’t too bad but didn’t get to the final list.
                                <br>
                                <br>
                                <audio controls>
                                    <source src="nobodys/preselected1.mp3" type="audio/mpeg">
                                    Your browser does not support the audio element.
                                </audio>
                                <br>
                                And others that deeply touched me as soon as I heard them, went straight to the final
                                selection.
                                <br>
                                <br>
                                <audio controls>
                                    <source src="nobodys/ohmygood.mp3" type="audio/mpeg">
                                    Your browser does not support the audio element.
                                </audio>
                                <br>
                                <br>
                                <br>
                                <h6>Listening with professional musicians</h6>
                                <br>
                                <h5>When I finished my first pre-curation I invited two professional musicians to listen
                                    to
                                    the selection with me and analyze the results musically.</h5>
                                <br>
                                <br>
                            </h5>
                            <img class="medium-pic" src="nobodys/musicians_listening.jpg" alt="">
                            <br>
                            Ale Daffra and Fito Reynals listening to the transformer continuations.
                            <br>
                            <br>
                            <h5>
                                Some of the comments about the results:
                                <br>
                                <p style="font-style: italic;">“Impressionist colors with romantic touches that at times
                                    reminds of Chopin”.</p>
                                <br>
                                <p style="font-style: italic;">“Impressionist colors with romantic touches that at times
                                    reminds of Chopin”.</p>


                                “Simple, light and expressive textures with a free and unpredictable time that conveys
                                calm and tranquility”.

                                Finally, they helped me to make the selection of the 9 tracks.
                            </h5>

                        </h5>
                </div>
            </div>
        </div>
        <div class="loader">
            <div class="loader-bar"></div>
        </div>
    </div> <!-- JS -->
    <script>
        (function (i, s, o, g, r, a, m) {
            i['GoogleAnalyticsObject'] = r;
            i[r] = i[r] || function () {
                (i[r].q = i[r].q || []).push(arguments)
            }, i[r].l = 1 * new Date();
            a = s.createElement(o), m = s.getElementsByTagName(o)[0];
            a.async = 1;
            a.src = g;
            m.parentNode.insertBefore(a, m)
        })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');
        ga('create', 'UA-83557691-1', 'auto');
        ga('send', 'pageview');

    </script>
    <script src="js/jquery.min.js"></script>
    <script src="js/isotope.pkgd.min.js"></script>
    <!-- <script type="text/javascript" src="js/inspiring-online.js"></script> -->
</body>

</html>
